{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Examine and Handle missing values (e.g., fill the missing value, add a corresponding label).\n",
    "2. Handle non-numeric values (e.g. one-hot encoding, Boolean indicator).\n",
    "3. Further processing (e.g. standardize features).\n",
    "'''\n",
    "\n",
    "columns = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "def handle_missing_values():\n",
    "    pass\n",
    "\n",
    "def csv_convert(input_path, output_path):\n",
    "    \"\"\"\n",
    "    将数据文件转换为 CSV 格式\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取数据文件\n",
    "        df = pd.read_csv(input_path, header=None, names=columns, skipinitialspace=True)\n",
    "        # 保存为 CSV 文件\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"成功将 {input_path} 转换为 {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"转换失败: {e}\")\n",
    "\n",
    "def missing_value_processing(input_path, output_path):\n",
    "    \"\"\"\n",
    "    处理缺失值\n",
    "    \"\"\"\n",
    "    # 需要避开第一行，因为它是列名\n",
    "    try:\n",
    "        # 读取数据文件\n",
    "        df = pd.read_csv(input_path, header=None, names=columns, skipinitialspace=True, skiprows=1)\n",
    "        # 将缺失值替换为 NaN\n",
    "        df.replace('?', pd.NA, inplace=True)\n",
    "        \n",
    "        # 对于数值变量，使用均值填充缺失值\n",
    "        numerical_columns = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "        for col in numerical_columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            mean_value = df[col].mean()\n",
    "            df[col] = df[col].fillna(mean_value)\n",
    "\n",
    "        # 对于分类变量，使用众数填充缺失值\n",
    "        categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']\n",
    "        for col in categorical_columns:\n",
    "            mode_value = df[col].mode()[0]\n",
    "            #print(f\"Mode value for {col}: {mode_value}\")\n",
    "            df[col] = df[col].fillna(mode_value)\n",
    "        \n",
    "        # 保存处理后的数据\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"成功处理 {input_path} 的缺失值并保存为 {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理{input_path}缺失值失败: {e}\")\n",
    "\n",
    "def data_type_conversion(input_path, output_path):\n",
    "    \"\"\"\n",
    "    数据类型转换\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取数据文件\n",
    "        df = pd.read_csv(input_path, header=None, names=columns, skipinitialspace=True, skiprows=1)\n",
    "        \n",
    "        # 对分类型变量进行转换\n",
    "        categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']\n",
    "        for col in categorical_columns:\n",
    "            # 1. 如果只有两种取值，则转换为布尔类型\n",
    "            if df[col].nunique() == 2:\n",
    "                df[col] = df[col].map({df[col].unique()[0]: 0, df[col].unique()[1]: 1})\n",
    "            # 2. 否则，进行独热编码\n",
    "            else:\n",
    "                dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "                # 进行0-1编码而非True-False编码\n",
    "                dummies = dummies.astype(int)\n",
    "                df = pd.concat([df, dummies], axis=1)\n",
    "                df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "        # 对数值变量进行标准化处理\n",
    "        numerical_columns = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "        for col in numerical_columns:\n",
    "            df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "        \n",
    "        # 保存处理后的数据\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"成功将 {input_path} 的数据类型转换并保存为 {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"数据类型转换失败: {e}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a614a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f937b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load the dataset\n",
    "    train_data_path = './raw/adult.data'\n",
    "    test_data_path = './raw/adult.test'\n",
    "\n",
    "    # 如果数据集存在，输出提示信息\n",
    "    if os.path.exists(train_data_path) and os.path.exists(test_data_path):\n",
    "        print(\"数据集路径已存在，开始处理数据集...\")\n",
    "    else:\n",
    "        print(\"非法数据集路径，请检查路径合法性。\")\n",
    "        exit()\n",
    "\n",
    "    # 读取数据集并转换成csv格式\n",
    "    train_csv_path = './data/adult_train.csv'\n",
    "    test_csv_path = './data/adult_test.csv'\n",
    "    csv_convert(train_data_path, train_csv_path)\n",
    "    csv_convert(test_data_path, test_csv_path)\n",
    "\n",
    "    # 1.对于训练集和测试集，先进行缺失值处理\n",
    "    # 此处缺失值表示为 \"?\"；对于数值变量，使用均值填充；对于分类变量，使用众数填充\n",
    "    filled_train_csv_path = './data/adult_train_filled.csv'\n",
    "    filled_test_csv_path = './data/adult_test_filled.csv'\n",
    "    missing_value_processing(train_csv_path, filled_train_csv_path)\n",
    "    missing_value_processing(test_csv_path, filled_test_csv_path)\n",
    "\n",
    "    # 2. 对于训练集和测试集，进行数据预处理\n",
    "    # 2.1 对于二元类变量，进行boolean编码；对于多元类变量，进行one-hot编码\n",
    "    # 2.2 对于数值变量，进行标准化处理\n",
    "    processed_train_csv_path = './data/adult_train_processed.csv'\n",
    "    processed_test_csv_path = './data/adult_test_processed.csv'\n",
    "    data_type_conversion(filled_train_csv_path, processed_train_csv_path)\n",
    "    data_type_conversion(filled_test_csv_path, processed_test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065c1bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f729d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对数据进行可视化\n",
    "1.Visualize high-dimensional data in a 2D and/or 3D space using t-SNE\n",
    "2. Create a scatter plot of the resulting embedding, coloring points by class labels if applicable.\n",
    "3. Analyze the visualization to identify patterns or clusters.\n",
    "'''\n",
    "\n",
    "'''\n",
    "对数据进行可视化\n",
    "1.Visualize high-dimensional data in a 2D and/or 3D space using t-SNE\n",
    "2. Create a scatter plot of the resulting embedding, coloring points by class labels if applicable.\n",
    "3. Analyze the visualization to identify patterns or clusters.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def visualize_tsne_2d(data, labels=None, title='t-SNE Visualization (2D)', \n",
    "                     save_path=None, colormap='tab20', balance_classes=False,\n",
    "                     point_size=30, alpha=0.5, legend_loc='best'):\n",
    "    \"\"\"\n",
    "    优化后的2D t-SNE可视化函数，支持类别不平衡处理\n",
    "    \n",
    "    Parameters新增:\n",
    "    balance_classes : bool, 是否进行类别平衡采样\n",
    "    point_size : int/array, 数据点大小\n",
    "    alpha : float, 透明度\n",
    "    legend_loc : str, 图例位置\n",
    "    \"\"\"\n",
    "    # 类别平衡处理\n",
    "    if balance_classes and labels is not None:\n",
    "        data, labels = _balance_classes(data, labels)\n",
    "\n",
    "    # t-SNE降维\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1200)\n",
    "    embedded_data = tsne.fit_transform(data)\n",
    "    \n",
    "    # 创建画布\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    if labels is not None:\n",
    "        # 按类别样本量倒序排列（先画多数类）\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        sorted_labels = unique_labels[np.argsort(-counts)]\n",
    "        \n",
    "        # 创建离散颜色映射\n",
    "        cmap = plt.get_cmap('Set1')  # 使用对比度更高的离散调色板\n",
    "        colors = cmap(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "        # 分层绘制各个类别\n",
    "        for idx, label in enumerate(sorted_labels):\n",
    "            mask = labels == label\n",
    "            plt.scatter(embedded_data[mask, 0], embedded_data[mask, 1],\n",
    "                        c=[colors[idx]], label=str(label),\n",
    "                        s=point_size, alpha=alpha, edgecolors='w', linewidth=0.3)\n",
    "            \n",
    "        # 添加图例\n",
    "        plt.legend(title='Class Labels', loc=legend_loc,\n",
    "                  frameon=True, framealpha=0.8)\n",
    "    else:\n",
    "        plt.scatter(embedded_data[:, 0], embedded_data[:, 1],\n",
    "                   s=point_size, alpha=alpha, edgecolors='w', linewidth=0.3)\n",
    "    \n",
    "    # 添加标签和网格\n",
    "    plt.title(title, pad=20)\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300, facecolor='white')\n",
    "    \n",
    "    plt.show()\n",
    "    return embedded_data\n",
    "\n",
    "def _balance_classes(data, labels):\n",
    "    \"\"\"内部使用的类别平衡函数\"\"\"\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    min_count = np.min(counts)\n",
    "    \n",
    "    sampled_indices = []\n",
    "    for label in unique_labels:\n",
    "        indices = np.where(labels == label)[0]\n",
    "        if len(indices) > min_count:\n",
    "            indices = np.random.choice(indices, min_count, replace=False)\n",
    "        sampled_indices.append(indices)\n",
    "    \n",
    "    sampled_indices = np.concatenate(sampled_indices)\n",
    "    return data[sampled_indices], labels[sampled_indices]\n",
    "\n",
    "\n",
    "def visualize_tsne_3d(data, labels=None, title='t-SNE Visualization (3D)', save_path=None, colormap='viridis', balance_classes=True):\n",
    "    \"\"\"\n",
    "    Visualize high-dimensional data in 3D using t-SNE.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        High-dimensional data to visualize.\n",
    "    labels : array-like, optional\n",
    "        Class labels for each data point.\n",
    "    title : str, optional\n",
    "        Title for the plot.\n",
    "    save_path : str, optional\n",
    "        Path to save the visualization.\n",
    "    colormap : str, optional\n",
    "        Colormap to use for the scatter plot.\n",
    "    \"\"\"\n",
    "    if balance_classes and labels is not None:\n",
    "        data, labels = _balance_classes(data, labels)\n",
    "    \n",
    "    # Apply t-SNE for dimensionality reduction to 3D\n",
    "    tsne = TSNE(n_components=3, random_state=42, perplexity=30, max_iter=1200)\n",
    "    embedded_data = tsne.fit_transform(data)\n",
    "    \n",
    "    # Create a 3D scatter plot\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    if labels is not None:\n",
    "        # If labels are provided, color points by labels\n",
    "        scatter = ax.scatter(embedded_data[:, 0], embedded_data[:, 1], embedded_data[:, 2], \n",
    "                  c=labels, cmap='Set1', alpha=0.5, s=10)\n",
    "        plt.colorbar(scatter, label='Class Labels')\n",
    "    else:\n",
    "        # If no labels, use a single color\n",
    "        ax.scatter(embedded_data[:, 0], embedded_data[:, 1], embedded_data[:, 2], \n",
    "                   alpha=0.8, s=50)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('t-SNE Feature 1')\n",
    "    ax.set_ylabel('t-SNE Feature 2')\n",
    "    ax.set_zlabel('t-SNE Feature 3')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return embedded_data\n",
    "\n",
    "def analyze_clusters(embedded_data, labels=None):\n",
    "    \"\"\"\n",
    "    Analyze the t-SNE embedding to identify patterns or clusters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    embedded_data : array-like\n",
    "        Low-dimensional embedding from t-SNE.\n",
    "    labels : array-like, optional\n",
    "        Class labels for each data point.\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        print(\"No labels provided for cluster analysis.\")\n",
    "        return\n",
    "    \n",
    "    # Calculate cluster statistics\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(f\"Number of clusters/classes: {len(unique_labels)}\")\n",
    "    \n",
    "    # Compute basic statistics for each cluster\n",
    "    for label in unique_labels:\n",
    "        cluster_points = embedded_data[labels == label]\n",
    "        center = np.mean(cluster_points, axis=0)\n",
    "        std_dev = np.std(cluster_points, axis=0)\n",
    "        count = len(cluster_points)\n",
    "        \n",
    "        print(f\"\\nCluster/Class {label}:\")\n",
    "        print(f\"  Number of points: {count}\")\n",
    "        print(f\"  Center: {center}\")\n",
    "        print(f\"  Standard deviation: {std_dev}\")\n",
    "        \n",
    "    # Visual analysis with a pairplot if using 3D embedding\n",
    "    if embedded_data.shape[1] >= 2:\n",
    "        df = pd.DataFrame(embedded_data[:, :3], columns=[f'Component {i+1}' for i in range(min(3, embedded_data.shape[1]))])\n",
    "        if labels is not None:\n",
    "            df['Label'] = labels\n",
    "            sns.pairplot(df, hue='Label')\n",
    "            plt.suptitle('Pairwise Relationships Between t-SNE Components', y=1.02)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d415e5f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d932d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load data from the specified CSV files\n",
    "    train_data = pd.read_csv('./data/adult_train_processed.csv')\n",
    "    test_data = pd.read_csv('./data/adult_test_processed.csv')\n",
    "    \n",
    "    print(f\"Loaded training data shape: {train_data.shape}\")\n",
    "    print(f\"Loaded test data shape: {test_data.shape}\")\n",
    "    \n",
    "    # Assuming the last column is the target/label\n",
    "    X_train = train_data.iloc[:, :-7].values\n",
    "    y_train = train_data.iloc[:, 7].values\n",
    "    \n",
    "    X_test = test_data.iloc[:, :7].values\n",
    "    y_test = test_data.iloc[:, 7].values\n",
    "    \n",
    "    \n",
    "    print(\"\\n--- Training Data Visualization ---\")\n",
    "    print(\"Visualizing training data in 2D...\")\n",
    "    embedded_train_2d = visualize_tsne_2d(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        title='t-SNE Visualization of Adult Income Dataset - Training Data (2D)',\n",
    "        save_path='./figures/tsne_train_2d.png',\n",
    "        colormap='tab10'  # Using a discrete colormap better for categorical data\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(\"\\nVisualizing training data in 3D...\")\n",
    "    embedded_train_3d = visualize_tsne_3d(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        title='t-SNE Visualization of Adult Income Dataset - Training Data (3D)',\n",
    "        save_path='./figures/tsne_train_3d.png',\n",
    "        colormap='tab10'  # Using a discrete colormap better for categorical data\n",
    "    )\n",
    "    print(\"\\n--- Analyzing Clusters in Training Data ---\")\n",
    "    analyze_clusters(embedded_train_2d, y_train)\n",
    "    analyze_clusters(embedded_train_3d, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4b30c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6782ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
